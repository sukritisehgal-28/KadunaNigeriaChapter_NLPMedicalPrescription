{"cells":[{"cell_type":"markdown","id":"ce742e42-6350-4371-8b57-eebb7cfed660","metadata":{"id":"ce742e42-6350-4371-8b57-eebb7cfed660"},"source":["# Wiki Extractions"]},{"cell_type":"code","execution_count":null,"id":"6b304827-0c4f-433b-b61d-8cd67256cdbd","metadata":{"id":"6b304827-0c4f-433b-b61d-8cd67256cdbd","outputId":"a0117645-4a7a-4f27-bfd8-6eaaaca0aaf7","colab":{"referenced_widgets":["8e1d3bbce13a4ae7ae9d516f6848f707"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e1d3bbce13a4ae7ae9d516f6848f707","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/70 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Echinococcosis\n","Amoebiasis\n","Anthrax\n","Ascariasis\n","Bartonellosis\n","Schistosomiasis\n","Brucellosis\n","Burkholderia pseudomallei\n","Buruli ulcer\n","Chikungunya\n","Cholera\n","Coccidioidomycosis\n","Crimean–Congo hemorrhagic fever\n","Cryptosporidiosis\n","Cysticercosis\n","Dengue fever\n","Dermatophytosis\n","Diphtheria\n","Dracunculiasis\n","Ebola\n","Filariasis\n","Meningitis\n","Giardiasis\n","Dracunculiasis\n","Orthohantavirus\n","Helminthiasis\n","Hendra virus\n","Hepatitis\n","HIV/AIDS\n","Hookworm\n","Japanese encephalitis\n","Kaposi's sarcoma-associated herpesvirus\n","Lassa fever\n","Leishmaniasis\n","Leprosy\n","Leptospirosis\n","Loa loafilariasis\n","Lymphatic filariasis\n","Lymphogranuloma venereum\n","Malaria\n","Marburg virus\n","Measles\n","Melioidosis\n","Meningococcal disease\n","B virus\n","Mpox\n","Mycetoma\n","Norovirus\n","Onchocerciasis\n","Plague (disease)\n","Polio\n","Q fever\n","Rabies\n","Rift Valley fever\n","Rotavirus\n","Schistosomiasis\n","Scrub typhus\n","Strongyloidiasis\n","Syphilis\n","Tetanus\n","Toxoplasmosis\n","Trachoma\n","Tropical sprue\n","Trypanosomiasis\n","Tuberculosis\n","Typhoid fever\n","West Nile virus\n","Yaws\n","Yellow fever\n","Zika virus\n","Database created and data inserted successfully.\n"]}],"source":["import requests\n","import time\n","import json\n","from tqdm.notebook import tqdm as tqdm\n","import sqlite3\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","# from langchain.llms import Ollama\n","# from langchain import LLMChain, PromptTemplate\n","\n","# -----------------------\n","# 1. Extract Website Data\n","# -----------------------\n","df = pd.read_csv(\"E:\\\\My Workspaces\\\\Langchain\\\\conditions_wiki.csv\")\n","\n","# URL of the Wikipedia article\n","urls = [i for i in df['Link'].values]\n","\n","# Initialize a list to hold the JSON data for each article.\n","data_list = []\n","\n","for url in tqdm(urls):\n","    # Pause between requests to be polite to the server\n","    time.sleep(2)\n","    response = requests.get(url)\n","\n","    if response.status_code == 200:\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","\n","        # Extract the main article title\n","        main_title = soup.find('h1', {'id': 'firstHeading'}).get_text(strip=True)\n","\n","        # Extract the main content container\n","        content_div = soup.find('div', {'class': 'mw-parser-output'})\n","\n","        # Create a list to hold sections; each section is a dict with a heading and its content.\n","        sections = []\n","        current_section = {\"heading\": main_title, \"content\": \"\"}\n","\n","        # Process the children elements (headings and paragraphs) in the content container\n","        for element in content_div.find_all(lambda tag: tag.name in ['h2', 'h3', 'h4', 'h5', 'h6', 'p']):\n","            if element.name in ['h2', 'h3', 'h4', 'h5', 'h6']:\n","                # Save the previous section before starting a new one (if it has any content)\n","                if current_section[\"heading\"] or current_section[\"content\"]:\n","                    sections.append(current_section)\n","                heading_text = element.get_text(separator=\" \", strip=True)\n","                current_section = {\"heading\": heading_text, \"content\": \"\"}\n","            elif element.name == 'p':\n","                paragraph_text = element.get_text(strip=True)\n","                if paragraph_text:\n","                    # Append paragraphs; separate them with a newline if needed\n","                    if current_section[\"content\"]:\n","                        current_section[\"content\"] += \"\\n\" + paragraph_text\n","                    else:\n","                        current_section[\"content\"] = paragraph_text\n","        # Append the final section\n","        if current_section[\"heading\"] or current_section[\"content\"]:\n","            sections.append(current_section)\n","\n","        # Combine the extracted data into a dictionary\n","        extracted_data = {\n","            \"title\": main_title,\n","            \"sections\": sections\n","        }\n","\n","        # Optionally print extracted data\n","        # print(\"Extracted Data:\")\n","        # print(json.dumps(extracted_data, indent=2))\n","        print(main_title)\n","        # Append the JSON data for this article to the list\n","        data_list.append(extracted_data)\n","    else:\n","        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n","        # Depending on your use-case, you might continue or exit. Here we continue.\n","        continue\n","\n","    # ----------------------------------------------------------------\n","    # (Optional) 2. Cleaning Using an LLM (Commented Out)\n","    # ----------------------------------------------------------------\n","    # If you wish to perform cleaning on each section using the Ollama LLM,\n","    # uncomment and adjust the code below.\n","    #\n","    # section_prompt_template = PromptTemplate(\n","    #     input_variables=[\"section_data\"],\n","    #     template=\"\"\"\n","    # You are given raw section data in JSON format. Please perform simple cleaning and text corrections only.\n","    # Do not add any extra information or hallucinate details.\n","    # Your task is to fix typos, remove extra spaces, and ensure the text is grammatically correct while preserving the original content.\n","    # If multiple related headings can be combined as a nested section, do so, but do not lose any content.\n","    #\n","    # Return only the cleaned JSON in the following format (with literal braces escaped):\n","    # {{\n","    #   \"heading\": \"<cleaned section heading>\",\n","    #   \"content\": \"<cleaned section content>\"\n","    # }}\n","    #\n","    # Here is the raw section data:\n","    # {section_data}\n","    #\n","    # ONLY RETURN THE CLEANED JSON.\n","    # \"\"\"\n","    # )\n","    #\n","    # llm = Ollama(model=\"phi4\",  temperature=0)\n","    # section_chain = LLMChain(llm=llm, prompt=section_prompt_template)\n","    #\n","    # cleaned_sections = []\n","    # for section in extracted_data[\"sections\"]:\n","    #     section_json = json.dumps(section, indent=2)\n","    #     try:\n","    #         cleaned_section_response = section_chain.run(section_data=section_json)\n","    #         if not cleaned_section_response.strip():\n","    #             cleaned_sections.append(section)\n","    #             continue\n","    #         try:\n","    #             cleaned_section = json.loads(cleaned_section_response)\n","    #             cleaned_sections.append(cleaned_section)\n","    #         except Exception as e:\n","    #             cleaned_sections.append(section)\n","    #     except Exception as e:\n","    #         cleaned_sections.append(section)\n","    #\n","    # # Combine the cleaned sections with the title\n","    # cleaned_data = {\n","    #     \"title\": main_title,\n","    #     \"sections\": cleaned_sections\n","    # }\n","    # print(\"\\nCleaned Data from Ollama (per section):\")\n","    # print(json.dumps(cleaned_data, indent=2))\n","    # # If using cleaned data, consider saving cleaned_data to data_list instead of extracted_data.\n","    # # data_list.append(cleaned_data)\n","\n","# -----------------------\n","# 3. Create a Database and Save the Data\n","# -----------------------\n","\n","# Create (or open) an SQLite database\n","conn = sqlite3.connect('wikipedia_articles_base.db')\n","cursor = conn.cursor()\n","\n","# Create a table for articles if it does not exist.\n","# Here, we store the title and sections (as a JSON string).\n","cursor.execute('''\n","    CREATE TABLE IF NOT EXISTS articles (\n","        id INTEGER PRIMARY KEY AUTOINCREMENT,\n","        title TEXT,\n","        sections TEXT\n","    )\n","''')\n","\n","# Insert each article's data into the database.\n","for article in data_list:\n","    title = article['title']\n","    # Convert the sections list into a JSON string before storing.\n","    sections_json = json.dumps(article['sections'])\n","    cursor.execute('INSERT INTO articles (title, sections) VALUES (?, ?)', (title, sections_json))\n","\n","conn.commit()\n","conn.close()\n","\n","print(\"Database created and data inserted successfully.\")\n"]},{"cell_type":"code","execution_count":null,"id":"c8000a47-ff9e-4c24-a63b-265d36a27426","metadata":{"id":"c8000a47-ff9e-4c24-a63b-265d36a27426","outputId":"e8401063-e749-4037-ee61-b2fa53ce4645"},"outputs":[{"name":"stdout","output_type":"stream","text":["   id           title                                           sections\n","0   1  Echinococcosis  [{'heading': 'Echinococcosis', 'content': 'Ech...\n","1   2      Amoebiasis  [{'heading': 'Amoebiasis', 'content': 'Amoebia...\n","2   3         Anthrax  [{'heading': 'Anthrax', 'content': 'Anthraxis ...\n","3   4      Ascariasis  [{'heading': 'Ascariasis', 'content': 'Ascaria...\n","4   5   Bartonellosis  [{'heading': 'Bartonellosis', 'content': 'Bart...\n"]}],"source":["import sqlite3\n","import pandas as pd\n","import json\n","\n","# Connect to the database\n","conn = sqlite3.connect('wikipedia_articles_base.db')\n","\n","# Read the entire articles table into a DataFrame\n","df = pd.read_sql_query(\"SELECT * FROM articles\", conn)\n","\n","# Optionally, if you want to convert the JSON string back into Python objects for the 'sections' column:\n","df['sections'] = df['sections'].apply(json.loads)\n","\n","# Close the connection\n","conn.close()\n","\n","# Display the DataFrame\n","print(df.head())\n"]},{"cell_type":"code","execution_count":null,"id":"ac844da9-ae20-4798-b305-28870d6a38bf","metadata":{"id":"ac844da9-ae20-4798-b305-28870d6a38bf","outputId":"2aa12b57-3c01-40bb-db1b-3958d9b92a5f"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\vinit\\AppData\\Local\\Temp\\ipykernel_10704\\2580632381.py:53: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n","  llm_tagger = Ollama(model=\"llama3.2:3b\", temperature=0.1)\n","C:\\Users\\vinit\\AppData\\Local\\Temp\\ipykernel_10704\\2580632381.py:56: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n","  tag_chain = LLMChain(llm=llm_tagger, prompt=tagging_prompt_template)\n"]},{"name":"stdout","output_type":"stream","text":["Tagging complete and database updated.\n"]}],"source":["import sqlite3\n","import json\n","from langchain.llms import Ollama\n","from langchain import LLMChain, PromptTemplate\n","\n","# -------------------------------------------\n","# 1. Set Up the LLM Tagging Chain\n","# -------------------------------------------\n","tagging_prompt_template = PromptTemplate(\n","    input_variables=[\"section_content\"],\n","    template=\"\"\"\n","You are an advanced named entity recognition system. Given the following section content (provided as plain text), identify which of the following tags is applicable: \"treatment\", \"prevention\", \"diagnosis\", \"cause\", or \"drop\".\n","\n","Use the \"drop\" tag if the content doesn't fit into any of the other four categories.\n","Each section must have exactly **one** tag. Do not assign multiple tags.\n","\n","Return the result **strictly** as a single-word response in double quotes, like `\"cause\"`.\n","\n","Examples:\n","\n","1.\n","Text:\n","An adult worm resides in the small intestine of a definitive host. A single gravid proglottid releases eggs that are passed in the feces of the definitive host...\n","Tag:\n","\"cause\"\n","\n","2.\n","Text:\n","The most common form found in humans is cystic echinococcosis...\n","Tag:\n","\"diagnosis\"\n","\n","3.\n","Text:\n","Several different strategies are currently being used to prevent and control cystic echinococcosis (CE)...\n","Tag:\n","\"prevention\"\n","\n","4.\n","Text:\n","A number of therapy options are presently available. Treatment with albendazole...\n","Tag:\n","\"treatment\"\n","\n","Now, classify the following text:\n","\n","Section content:\n","{section_content}\n","\"\"\"\n",")\n","\n","# Initialize the LLM (adjust model and parameters as needed)\n","llm_tagger = Ollama(model=\"llama3.2:3b\", temperature=0.1)\n","\n","# Define chains\n","tag_chain = LLMChain(llm=llm_tagger, prompt=tagging_prompt_template)\n","\n","# Connect to the Database and Read JSON Data\n","conn = sqlite3.connect('wikipedia_articles_base.db')\n","cursor = conn.cursor()\n","cursor.execute(\"SELECT id, title, sections FROM articles\")\n","rows = cursor.fetchall()\n","\n","records = []\n","\n","# Process Each Record\n","for row in range(df.shape[0]):\n","    article_id, title, sections_json = df.iloc[row]['id'], df.iloc[row]['title'], df.iloc[row]['sections']\n","    sections = sections_json\n","\n","    updated = False\n","\n","    for section in sections:\n","        text_for_tagging = section.get(\"heading\", \"\") + \"\\n\" + section.get(\"content\", \"\")\n","        raw_tags = tag_chain.invoke({\"section_content\": text_for_tagging})\n","        section[\"tags\"] = raw_tags['text']\n","        updated = True\n","\n","        updated_section = {\n","            \"disease_name\": title,                           # from the article title\n","            \"section\": section.get(\"heading\", \"\"),                    # section heading\n","            \"section_tag\": raw_tags['text'],                   # tag returned by the LLM\n","            \"content\": section.get(\"content\", \"\")                     # Corrected text content returned by LLM\n","        }\n","        records.append(updated_section)\n","\n","print(\"Tagging complete and database updated.\")\n"]},{"cell_type":"code","execution_count":null,"id":"bf63007a-f08a-4cba-8442-4d5b75569cf4","metadata":{"id":"bf63007a-f08a-4cba-8442-4d5b75569cf4","outputId":"a1a483e9-d524-4f59-dc0a-ae0b78639259"},"outputs":[{"name":"stdout","output_type":"stream","text":["     disease_name             section   section_tag  \\\n","0  Echinococcosis      Echinococcosis  \"prevention\"   \n","1  Echinococcosis  Signs and symptoms   \"diagnosis\"   \n","2  Echinococcosis               Cause       \"cause\"   \n","3  Echinococcosis               Hosts       \"cause\"   \n","4  Echinococcosis          Life cycle       \"cause\"   \n","\n","                                             content  \n","0  Echinococcosisis aparasitic diseasecaused byta...  \n","1  In the human manifestation of the disease,E. g...  \n","2  Like many other parasite infections, the cours...  \n","3                                                     \n","4  An adult worm resides in the small intestine o...  \n"]}],"source":["# -------------------------------------------\n","# 3. Create (or Update) the DataFrame from the Updated Dictionary\n","# -------------------------------------------\n","df_sections = pd.DataFrame(records)\n","\n","# Now you have a DataFrame with columns:\n","# ['disease_name', 'section', 'section_tag', 'content']\n","print(df_sections.head())"]},{"cell_type":"code","execution_count":null,"id":"8eb6a1ac-c56c-434a-afbd-33902b6342d9","metadata":{"id":"8eb6a1ac-c56c-434a-afbd-33902b6342d9","outputId":"85f0a034-0c00-4b65-dc7c-758eb317e2cc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>disease_name</th>\n","      <th>section</th>\n","      <th>section_tag</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Echinococcosis</td>\n","      <td>Echinococcosis</td>\n","      <td>\"prevention\"</td>\n","      <td>Echinococcosisis aparasitic diseasecaused byta...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Echinococcosis</td>\n","      <td>Signs and symptoms</td>\n","      <td>\"diagnosis\"</td>\n","      <td>In the human manifestation of the disease,E. g...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Echinococcosis</td>\n","      <td>Cause</td>\n","      <td>\"cause\"</td>\n","      <td>Like many other parasite infections, the cours...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Echinococcosis</td>\n","      <td>Hosts</td>\n","      <td>\"cause\"</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Echinococcosis</td>\n","      <td>Life cycle</td>\n","      <td>\"cause\"</td>\n","      <td>An adult worm resides in the small intestine o...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1125</th>\n","      <td>Zika virus</td>\n","      <td>India, Bangladesh</td>\n","      <td>\"prevention\"</td>\n","      <td>On 22 March 2016, Reuters reported that Zika w...</td>\n","    </tr>\n","    <tr>\n","      <th>1126</th>\n","      <td>Zika virus</td>\n","      <td>East Asia</td>\n","      <td>\"prevention\"</td>\n","      <td>Between August and November 2016, 455 cases of...</td>\n","    </tr>\n","    <tr>\n","      <th>1127</th>\n","      <td>Zika virus</td>\n","      <td>See also</td>\n","      <td>\"drop\"</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1128</th>\n","      <td>Zika virus</td>\n","      <td>References</td>\n","      <td>\"drop\"</td>\n","      <td>This article incorporatespublic domain materia...</td>\n","    </tr>\n","    <tr>\n","      <th>1129</th>\n","      <td>Zika virus</td>\n","      <td>External links</td>\n","      <td>\"drop\"</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1130 rows × 4 columns</p>\n","</div>"],"text/plain":["        disease_name             section   section_tag  \\\n","0     Echinococcosis      Echinococcosis  \"prevention\"   \n","1     Echinococcosis  Signs and symptoms   \"diagnosis\"   \n","2     Echinococcosis               Cause       \"cause\"   \n","3     Echinococcosis               Hosts       \"cause\"   \n","4     Echinococcosis          Life cycle       \"cause\"   \n","...              ...                 ...           ...   \n","1125      Zika virus   India, Bangladesh  \"prevention\"   \n","1126      Zika virus           East Asia  \"prevention\"   \n","1127      Zika virus            See also        \"drop\"   \n","1128      Zika virus          References        \"drop\"   \n","1129      Zika virus      External links        \"drop\"   \n","\n","                                                content  \n","0     Echinococcosisis aparasitic diseasecaused byta...  \n","1     In the human manifestation of the disease,E. g...  \n","2     Like many other parasite infections, the cours...  \n","3                                                        \n","4     An adult worm resides in the small intestine o...  \n","...                                                 ...  \n","1125  On 22 March 2016, Reuters reported that Zika w...  \n","1126  Between August and November 2016, 455 cases of...  \n","1127                                                     \n","1128  This article incorporatespublic domain materia...  \n","1129                                                     \n","\n","[1130 rows x 4 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_sections"]},{"cell_type":"code","execution_count":null,"id":"c2fbf6aa-de2a-4199-b1a5-e1b9c1ca6c69","metadata":{"id":"c2fbf6aa-de2a-4199-b1a5-e1b9c1ca6c69"},"outputs":[],"source":["df_sections.to_csv(\"disease_wiki.csv\")"]},{"cell_type":"code","execution_count":null,"id":"8f06b9e6-ff99-4bad-bf21-cb26f5aca2d9","metadata":{"id":"8f06b9e6-ff99-4bad-bf21-cb26f5aca2d9"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}